{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0742c7d3",
   "metadata": {},
   "source": [
    "## Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f452c80",
   "metadata": {},
   "source": [
    "**Bayes' theorem** is a mathematical formula that helps us update the probability of an event based on new information. It's a cornerstone of Bayesian statistics.\n",
    "\n",
    "In simpler terms, it allows us to revise our beliefs about something (like the probability of rain) after we get new evidence (like seeing dark clouds).\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "```\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "```\n",
    "\n",
    "Where:\n",
    "* P(A|B) is the probability of event A happening, given that event B has already happened (posterior probability)\n",
    "* P(B|A) is the probability of event B happening, given that event A has already happened (likelihood)\n",
    "* P(A) is the probability of event A happening (prior probability)\n",
    "* P(B) is the probability of event B happening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd99a2b",
   "metadata": {},
   "source": [
    "## Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8d1fd2",
   "metadata": {},
   "source": [
    "**Bayes' theorem** is expressed as:\n",
    "\n",
    "```\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "```\n",
    "\n",
    "Where:\n",
    "* **P(A|B)** is the probability of event A occurring, given that event B has occurred.\n",
    "* **P(B|A)** is the probability of event B occurring, given that event A has occurred.\n",
    "* **P(A)** is the probability of event A occurring.\n",
    "* **P(B)** is the probability of event B occurring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308e412f",
   "metadata": {},
   "source": [
    "## Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d76388",
   "metadata": {},
   "source": [
    "## Bayes' Theorem in Practice: A Medical Diagnosis Example\n",
    "\n",
    "Let's consider a simplified example of medical diagnosis.\n",
    "\n",
    "**Problem:** A patient exhibits symptoms consistent with the flu (fever, cough, body aches). What is the probability that the patient actually has the flu?\n",
    "\n",
    "**Using Bayes' Theorem:**\n",
    "\n",
    "* **P(Flu|Symptoms):** Probability of having the flu given the observed symptoms. This is what we want to find.\n",
    "* **P(Symptoms|Flu):** Probability of having these symptoms given that the patient has the flu.\n",
    "* **P(Flu):** Overall probability of having the flu in the population (prior probability).\n",
    "* **P(Symptoms):** Probability of having these symptoms regardless of whether the patient has the flu or not.\n",
    "\n",
    "**Applying the formula:**\n",
    "\n",
    "```\n",
    "P(Flu|Symptoms) = (P(Symptoms|Flu) * P(Flu)) / P(Symptoms)\n",
    "```\n",
    "\n",
    "To calculate these probabilities:\n",
    "\n",
    "* **P(Symptoms|Flu):** This information comes from medical studies that indicate the likelihood of these symptoms in flu patients.\n",
    "* **P(Flu):** This is the overall prevalence of the flu in the population at that time.\n",
    "* **P(Symptoms):** This is more complex to calculate directly, but it can often be estimated or approximated.\n",
    "\n",
    "By plugging in these values into the Bayes' theorem formula, we can calculate the probability of the patient having the flu given their symptoms.\n",
    "\n",
    "**Key points:**\n",
    "\n",
    "* Bayes' theorem allows us to update our belief about a disease (flu in this case) based on new evidence (symptoms).\n",
    "* It helps to incorporate prior knowledge (prevalence of the flu) into the calculation.\n",
    "* This approach is used in various medical diagnostic tools and systems.\n",
    "\n",
    "**Beyond medical diagnosis:**\n",
    "\n",
    "Bayes' theorem finds applications in numerous other fields, such as:\n",
    "\n",
    "* **Spam filtering:** Classifying emails as spam or not spam.\n",
    "* **Weather forecasting:** Predicting weather conditions based on current data.\n",
    "* **Finance:** Assessing investment risks.\n",
    "* **Machine learning:** Building probabilistic models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27c4235",
   "metadata": {},
   "source": [
    "## Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7948ee54",
   "metadata": {},
   "source": [
    "## Bayes' Theorem and Conditional Probability: A Close Relationship\n",
    "\n",
    "**Bayes' theorem is essentially a derived form of conditional probability.**\n",
    "\n",
    "* **Conditional probability** is the probability of an event occurring given that another event has already occurred. It's denoted as P(A|B), which means the probability of A given B.\n",
    "* **Bayes' theorem** takes this concept further by providing a way to calculate the probability of one event given another, when we know the probability of the second event given the first. In other words, it helps us \"reverse\" the conditional probability.\n",
    "\n",
    "**The formula for Bayes' theorem is derived from the definition of conditional probability.**\n",
    "\n",
    "To summarize:\n",
    "\n",
    "* **Conditional probability** is the foundation.\n",
    "* **Bayes' theorem** is a specific application of conditional probability that allows us to update probabilities based on new information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea23443",
   "metadata": {},
   "source": [
    "## Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c40584",
   "metadata": {},
   "source": [
    "## Choosing the Right Naive Bayes Classifier\n",
    "\n",
    "The choice of Naive Bayes classifier primarily depends on the nature of your data. Here's a breakdown:\n",
    "\n",
    "### 1. Multinomial Naive Bayes\n",
    "* **Best suited for:** Discrete data, especially when features represent frequencies or counts.\n",
    "* **Common applications:** Text classification (spam filtering, sentiment analysis), document categorization.\n",
    "* **Example:** Word counts in a document.\n",
    "\n",
    "### 2. Bernoulli Naive Bayes\n",
    "* **Best suited for:** Binary data, where features represent the presence or absence of something.\n",
    "* **Common applications:** Text classification with binary feature representation (word existence), document classification with binary features.\n",
    "* **Example:** Whether a word appears in a document or not.\n",
    "\n",
    "### 3. Gaussian Naive Bayes\n",
    "* **Best suited for:** Continuous data, assuming features are normally distributed.\n",
    "* **Common applications:** Classification problems with continuous features.\n",
    "* **Example:** Age, salary, temperature.\n",
    "\n",
    "### Key Considerations:\n",
    "* **Data distribution:** If your features are categorical or discrete, Multinomial Naive Bayes is often a good choice. For continuous features, Gaussian Naive Bayes is suitable.\n",
    "* **Feature representation:** If your features are binary (present or absent), Bernoulli Naive Bayes is appropriate.\n",
    "* **Performance:** Experiment with different classifiers and evaluate their performance on your specific dataset to make the final decision.\n",
    "\n",
    "**Additional Tips:**\n",
    "* **Feature engineering:** Consider transforming features to fit the assumptions of a particular Naive Bayes variant.\n",
    "* **Handling zero probabilities:** Implement smoothing techniques (like Laplace smoothing) to prevent issues with zero probabilities.\n",
    "* **Combining classifiers:** In some cases, combining multiple Naive Bayes classifiers can improve performance.\n",
    "\n",
    "By carefully considering these factors, you can select the most appropriate Naive Bayes classifier for your classification problem and achieve better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44177c23",
   "metadata": {},
   "source": [
    "## Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "\n",
    "A 3 3 4 4 3 3 3\n",
    "\n",
    "B 2 2 1 2 2 2 3\n",
    "\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401cc16f",
   "metadata": {},
   "source": [
    "## Understanding the Problem\n",
    "We have a Naive Bayes classification problem with two features (X1 and X2) and two classes (A and B). We need to predict the class for a new instance with X1=3 and X2=4.\n",
    "\n",
    "## Solution\n",
    "\n",
    "### Step 1: Calculate Probabilities\n",
    "We'll use the provided data to calculate the probabilities for each feature value given a class.\n",
    "\n",
    "**For Class A:**\n",
    "* P(X1=3|A) = 4/10 = 0.4\n",
    "* P(X2=4|A) = 3/10 = 0.3\n",
    "\n",
    "**For Class B:**\n",
    "* P(X1=3|B) = 1/7 ≈ 0.143\n",
    "* P(X2=4|B) = 3/7 ≈ 0.429\n",
    "\n",
    "### Step 2: Apply Bayes' Theorem\n",
    "Assuming equal prior probabilities for A and B (P(A) = P(B) = 0.5), we can calculate the posterior probabilities:\n",
    "\n",
    "* P(A|X1=3, X2=4) = P(X1=3|A) * P(X2=4|A) * P(A)\n",
    "* P(B|X1=3, X2=4) = P(X1=3|B) * P(X2=4|B) * P(B)\n",
    "\n",
    "Since P(A) = P(B), we can ignore them for comparison.\n",
    "\n",
    "* P(A|X1=3, X2=4) = 0.4 * 0.3 = 0.12\n",
    "* P(B|X1=3, X2=4) ≈ 0.143 * 0.429 ≈ 0.061\n",
    "\n",
    "### Step 3: Make a Prediction\n",
    "Since P(A|X1=3, X2=4) > P(B|X1=3, X2=4), **Naive Bayes would predict the new instance to belong to class A**.\n",
    "\n",
    "**Note:** Naive Bayes assumes independence between features, which might not hold true in real-world scenarios. This simplification can impact the accuracy of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ca95b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
