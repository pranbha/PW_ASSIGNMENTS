{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "970de0b2",
   "metadata": {},
   "source": [
    "### Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a2e830",
   "metadata": {},
   "source": [
    "ANOVA (Analysis of Variance) is a statistical method used to compare means across two or more groups. To use ANOVA reliably, several assumptions must be met:\n",
    "\n",
    "1. Independence: The observations within each group are independent of each other. This means that the value of one observation does not influence the value of another observation within the same group.\n",
    "\n",
    "2. Normality: The data within each group should be approximately normally distributed. This means that when you plot the data for each group in a histogram, it should resemble a bell curve.\n",
    "\n",
    "3. Homogeneity of Variance (Homoscedasticity): The variance among the groups should be approximately equal. This means that the spread of data points around the mean should be similar across all groups.\n",
    "\n",
    "In practice, ANOVA is robust to violations of these assumptions to some extent, especially when sample sizes are large. However, if violations are severe, it's advisable to use alternative methods such as non-parametric tests or transformations to address the issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cea886",
   "metadata": {},
   "source": [
    "### Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d65fc0",
   "metadata": {},
   "source": [
    "The three types of ANOVA are:\n",
    "\n",
    "1. One-Way ANOVA: This type of ANOVA is used when comparing means across two or more independent groups on a single continuous dependent variable. It answers the question of whether there are any statistically significant differences between the means of the groups. One-way ANOVA is appropriate when you have one categorical independent variable (with three or more levels) and one continuous dependent variable. For example, you might use one-way ANOVA to compare the effectiveness of three different teaching methods on student test scores.\n",
    "\n",
    "2. Two-Way ANOVA: This type of ANOVA is used when you have two independent categorical variables (factors) and one continuous dependent variable. It allows you to examine the main effects of each factor as well as any interaction between the factors. Two-way ANOVA is suitable for situations where you want to explore the effects of two categorical variables simultaneously on a continuous outcome. For example, you might use two-way ANOVA to investigate the effects of both gender and treatment type on patient recovery time.\n",
    "\n",
    "3. N-Way ANOVA (or MANOVA for Multivariate Analysis of Variance): This type of ANOVA extends the principles of one-way and two-way ANOVA to situations with more than two independent variables or factors. N-Way ANOVA allows for the analysis of the effects of multiple categorical independent variables on one or more continuous dependent variables. It's used when you have multiple factors influencing a single outcome or multiple outcomes that you want to analyze simultaneously. For example, in psychology, you might use MANOVA to assess the effects of both age and gender on various psychological test scores.\n",
    "\n",
    "In summary:\n",
    "- One-Way ANOVA: One categorical independent variable, one continuous dependent variable.\n",
    "- Two-Way ANOVA: Two categorical independent variables, one continuous dependent variable.\n",
    "- N-Way ANOVA (MANOVA): Multiple categorical independent variables, one or more continuous dependent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd51d0c6",
   "metadata": {},
   "source": [
    "### Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94b1f99",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA refers to the process of breaking down the total variance in the data into different components that can be attributed to different sources. Understanding this concept is crucial because it allows researchers to quantify and understand the contributions of various factors to the overall variability in the data. This helps in drawing more accurate conclusions about the relationships between variables and in identifying which factors are most influential in explaining the observed differences.\n",
    "\n",
    "In ANOVA, the total variability in the data is partitioned into two main components:\n",
    "\n",
    "1. Between-group variance: This component represents the variability in the data that can be attributed to differences between the group means. It reflects the extent to which the group means differ from each other. In ANOVA terms, it's often referred to as the \"treatment effect\" or \"factor effect.\" When this component is large relative to the within-group variance, it suggests that the independent variable (or factors) under consideration has a significant impact on the dependent variable.\n",
    "\n",
    "2. Within-group variance: This component represents the variability in the data that is not accounted for by differences between the group means. It reflects the variability within each group or category. It includes random variation as well as any variability that can't be explained by the independent variable(s) in the model. This component is also known as \"error variance\" or \"residual variance.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688a863e",
   "metadata": {},
   "source": [
    "### Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64430447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 78.66666666666667\n",
      "Explained Sum of Squares (SSE): 18.666666666666668\n",
      "Residual Sum of Squares (SSR): 60.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Example data\n",
    "data = {\n",
    "    'group1': [10, 12, 14, 16],\n",
    "    'group2': [13, 15, 17, 19],\n",
    "    'group3': [11, 13, 15, 17]\n",
    "}\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate overall mean\n",
    "overall_mean = np.mean(df.values)\n",
    "\n",
    "# Calculate total sum of squares (SST)\n",
    "SST = np.sum((df.values - overall_mean) ** 2)\n",
    "\n",
    "# Calculate explained sum of squares (SSE)\n",
    "group_means = df.mean(axis=0)\n",
    "SSE = np.sum((group_means - overall_mean) ** 2 * len(df))\n",
    "\n",
    "# Calculate residual sum of squares (SSR)\n",
    "SSR = SST - SSE\n",
    "\n",
    "print(\"Total Sum of Squares (SST):\", SST)\n",
    "print(\"Explained Sum of Squares (SSE):\", SSE)\n",
    "print(\"Residual Sum of Squares (SSR):\", SSR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc1b6df",
   "metadata": {},
   "source": [
    "### Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c77e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data\n",
    "data = {\n",
    "    'A': ['A1', 'A1', 'A2', 'A2'],\n",
    "    'B': ['B1', 'B2', 'B1', 'B2'],\n",
    "    'value': [10, 12, 15, 17]\n",
    "}\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('value ~ C(A) + C(B) + C(A):C(B)', data=df).fit()\n",
    "\n",
    "# Perform ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract main effects and interaction effects\n",
    "main_effects = anova_table[['sum_sq']].iloc[:2]  # Extract rows for main effects\n",
    "interaction_effect = anova_table['sum_sq'].iloc[2]  # Extract interaction effect\n",
    "\n",
    "print(\"Main Effects:\")\n",
    "print(main_effects)\n",
    "print(\"\\nInteraction Effect:\")\n",
    "print(interaction_effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a512530",
   "metadata": {},
   "source": [
    "### Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c50954",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, the F-statistic is used to test the null hypothesis that the means of all the groups are equal against the alternative hypothesis that at least one group mean is different from the others. The p-value associated with the F-statistic indicates the probability of observing such an extreme result (or more extreme) under the assumption that the null hypothesis is true.\n",
    "\n",
    "Given the obtained F-statistic of 5.23 and a p-value of 0.02:\n",
    "- The F-statistic of 5.23 indicates that there is some degree of difference between the group means.\n",
    "- The p-value of 0.02 indicates that the probability of observing an F-statistic as extreme as 5.23 (or more extreme) under the assumption that the null hypothesis is true is 0.02, or 2%.\n",
    "\n",
    "Interpreting these results:\n",
    "- Since the p-value (0.02) is less than the significance level (often chosen as 0.05), we reject the null hypothesis.\n",
    "- Therefore, we have evidence to suggest that at least one group mean is different from the others.\n",
    "- However, the one-way ANOVA does not tell us which specific group(s) differ from each other. To determine this, post-hoc tests such as Tukey's HSD (Honestly Significant Difference) test or Bonferroni correction can be conducted.\n",
    "\n",
    "In summary, based on the obtained F-statistic and p-value:\n",
    "- We conclude that there are statistically significant differences between the groups.\n",
    "- Further analyses, such as post-hoc tests, are needed to determine which specific groups differ from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e874c37b",
   "metadata": {},
   "source": [
    "### Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef3b3a8",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA requires careful consideration, as missing data can introduce bias and reduce the statistical power of the analysis. There are several methods to handle missing data in repeated measures ANOVA, each with its own potential consequences:\n",
    "\n",
    "1. Complete Case Analysis (CCA):\n",
    "   - In CCA, only cases with complete data across all time points are included in the analysis, and cases with any missing data are excluded.\n",
    "   - Potential consequences:\n",
    "     - Loss of statistical power: Excluding cases with missing data may reduce the sample size and statistical power of the analysis.\n",
    "     - Biased estimates: If missing data are not completely random (i.e., related to the outcome or predictors), estimates of effects may be biased.\n",
    "\n",
    "2. Mean Imputation:\n",
    "   - Missing values are replaced with the mean of observed values for the variable.\n",
    "   - Potential consequences:\n",
    "     - Underestimation of standard errors: Mean imputation reduces variability in the data, leading to underestimation of standard errors and potentially inflated Type I error rates.\n",
    "     - Distortion of relationships: Mean imputation can distort relationships between variables, particularly if missingness is related to the outcome or predictors.\n",
    "\n",
    "3. Last Observation Carried Forward (LOCF):\n",
    "   - Missing values are replaced with the last observed value for the variable.\n",
    "   - Potential consequences:\n",
    "     - Overestimation of treatment effects: LOCF assumes that missing data would follow the same trajectory as observed data, which may not be valid. This can lead to overestimation of treatment effects, particularly if missingness is related to treatment response.\n",
    "\n",
    "4. Multiple Imputation:\n",
    "   - Missing values are imputed multiple times to generate several complete datasets, each of which is analyzed separately. The results are then combined to produce overall estimates.\n",
    "   - Potential consequences:\n",
    "     - Complexity: Multiple imputation requires additional statistical software and expertise to implement properly.\n",
    "     - Assumption violations: The validity of multiple imputation depends on the assumption that the missing data mechanism is ignorable, meaning that missingness is not related to unobserved data after accounting for observed data. Violations of this assumption can lead to biased estimates.\n",
    "\n",
    "5. Model-Based Imputation:\n",
    "   - Missing values are imputed using a model that accounts for the underlying structure of the data.\n",
    "   - Potential consequences:\n",
    "     - Model misspecification: Model-based imputation relies on correctly specifying the underlying data-generating process. Misspecification of the model can lead to biased estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268d19f4",
   "metadata": {},
   "source": [
    "### Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef339b52",
   "metadata": {},
   "source": [
    "Common post-hoc tests used after ANOVA are:\n",
    "\n",
    "1. **Tukey's Honestly Significant Difference (HSD) Test**:\n",
    "   - Tukey's HSD test compares all possible pairs of group means to determine if they are significantly different from each other.\n",
    "   - It is used when you have conducted a one-way ANOVA and found a significant overall effect of the independent variable.\n",
    "   - Example: Suppose you conducted a one-way ANOVA to compare the effectiveness of three different teaching methods on student test scores. After finding a significant overall effect, you would use Tukey's HSD test to determine which specific pairs of teaching methods differ significantly in terms of their effects on test scores.\n",
    "\n",
    "2. **Bonferroni Correction**:\n",
    "   - The Bonferroni correction adjusts the significance level for multiple comparisons to control the familywise error rate.\n",
    "   - It is used when conducting multiple pairwise comparisons in a one-way ANOVA or when conducting multiple tests on related hypotheses.\n",
    "   - Example: If you have multiple pairwise comparisons to make after conducting a one-way ANOVA, you might use the Bonferroni correction to adjust the significance level to maintain an overall alpha level of 0.05.\n",
    "\n",
    "3. **Dunnett's Test**:\n",
    "   - Dunnett's test compares each treatment group to a control group, rather than all possible pairs of groups.\n",
    "   - It is used when one group serves as a control or reference group, and the primary interest is in comparing the other groups to the control group.\n",
    "   - Example: In a clinical trial comparing the effectiveness of several drug treatments to a placebo, Dunnett's test would be used to compare each drug treatment group to the placebo control group.\n",
    "\n",
    "4. **Scheffé's Test**:\n",
    "   - Scheffé's test is a conservative post-hoc test that controls the familywise error rate for all possible comparisons.\n",
    "   - It is used when you want to make multiple comparisons while maintaining control over the probability of making at least one Type I error.\n",
    "   - Example: If you have several treatment groups and want to compare all possible pairs of groups after conducting a one-way ANOVA, Scheffé's test can be used to control the overall Type I error rate.\n",
    "\n",
    "When to use each post-hoc test depends on the specific research question, the nature of the data, and the assumptions underlying each test. It's important to choose a post-hoc test that is appropriate for the research design and to interpret the results in light of the chosen test's assumptions and limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5dd47e",
   "metadata": {},
   "source": [
    "### Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d008f036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 15.658561165574055\n",
      "p-value: 6.841245188139539e-07\n",
      "There is significant evidence to reject the null hypothesis, suggesting that there are significant differences between the mean weight loss of the three diets.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Example data\n",
    "weight_loss_a = np.random.normal(loc=5, scale=2, size=50)  # Mean weight loss for diet A\n",
    "weight_loss_b = np.random.normal(loc=6, scale=2, size=50)  # Mean weight loss for diet B\n",
    "weight_loss_c = np.random.normal(loc=7, scale=2, size=50)  # Mean weight loss for diet C\n",
    "\n",
    "# Combine data from all diets\n",
    "weight_loss_data = np.concatenate([weight_loss_a, weight_loss_b, weight_loss_c])\n",
    "\n",
    "# Generate group labels\n",
    "groups = ['A'] * 50 + ['B'] * 50 + ['C'] * 50\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(weight_loss_a, weight_loss_b, weight_loss_c)\n",
    "\n",
    "# Report results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret results\n",
    "if p_value < 0.05:\n",
    "    print(\"There is significant evidence to reject the null hypothesis, suggesting that there are significant differences \"\n",
    "          \"between the mean weight loss of the three diets.\")\n",
    "else:\n",
    "    print(\"There is not enough evidence to reject the null hypothesis, suggesting that there are no significant differences \"\n",
    "          \"between the mean weight loss of the three diets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e718e36",
   "metadata": {},
   "source": [
    "### Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4fac38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               sum_sq    df         F    PR(>F)\n",
      "C(Software)                  4.600606   2.0  0.532542  0.589080\n",
      "C(Experience)                1.359515   1.0  0.314741  0.576279\n",
      "C(Software):C(Experience)   15.102201   2.0  1.748150  0.180369\n",
      "Residual                   362.836289  84.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data\n",
    "np.random.seed(0)\n",
    "software = np.random.choice(['A', 'B', 'C'], size=90)\n",
    "experience = np.random.choice(['novice', 'experienced'], size=90)\n",
    "time = np.random.normal(loc=10, scale=2, size=90)  # Mean time to complete the task\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'Software': software, 'Experience': experience, 'Time': time})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=df).fit()\n",
    "\n",
    "# Perform ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Report results\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb4018",
   "metadata": {},
   "source": [
    "### Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "904254b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -3.597192759749614\n",
      "p-value: 0.0004062796020362504\n",
      "There is significant evidence to reject the null hypothesis, suggesting that there are significant differences in test scores between the control group and the experimental group.\n",
      "Follow-up analyses needed.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Example data\n",
    "np.random.seed(0)\n",
    "control_scores = np.random.normal(loc=70, scale=10, size=100)  # Test scores for control group\n",
    "experimental_scores = np.random.normal(loc=75, scale=10, size=100)  # Test scores for experimental group\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "# Report results\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret results\n",
    "if p_value < 0.05:\n",
    "    print(\"There is significant evidence to reject the null hypothesis, suggesting that there are significant differences \"\n",
    "          \"in test scores between the control group and the experimental group.\")\n",
    "else:\n",
    "    print(\"There is not enough evidence to reject the null hypothesis, suggesting that there are no significant differences \"\n",
    "          \"in test scores between the control group and the experimental group.\")\n",
    "\n",
    "# Follow up with post-hoc test (if significant)\n",
    "if p_value < 0.05:\n",
    "    # You can perform additional analyses here, such as pairwise comparisons using post-hoc tests like Tukey's HSD.\n",
    "    print(\"Follow-up analyses needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53830ca",
   "metadata": {},
   "source": [
    "### Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post- hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fc86a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data\n",
    "np.random.seed(0)\n",
    "store_a_sales = np.random.normal(loc=100, scale=20, size=30)  # Daily sales for Store A\n",
    "store_b_sales = np.random.normal(loc=110, scale=20, size=30)  # Daily sales for Store B\n",
    "store_c_sales = np.random.normal(loc=120, scale=20, size=30)  # Daily sales for Store C\n",
    "\n",
    "# Combine data from all stores\n",
    "sales_data = np.concatenate([store_a_sales, store_b_sales, store_c_sales])\n",
    "\n",
    "# Generate store labels\n",
    "stores = ['A'] * 30 + ['B'] * 30 + ['C'] * 30\n",
    "\n",
    "# Generate day labels\n",
    "days = np.tile(np.arange(30), 3)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'Store': stores, 'Day': days, 'Sales': sales_data})\n",
    "\n",
    "# Fit the repeated measures ANOVA model\n",
    "model = ols('Sales ~ C(Store) + C(Day) + C(Store):C(Day)', data=df).fit()\n",
    "\n",
    "# Perform ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=3)\n",
    "\n",
    "# Report results\n",
    "print(anova_table)\n",
    "\n",
    "# Follow up with post-hoc test (if significant)\n",
    "if anova_table['PR(>F)']['C(Store):C(Day)'] < 0.05:\n",
    "    # You can perform additional analyses here, such as pairwise comparisons using post-hoc tests like Tukey's HSD.\n",
    "    print(\"Follow-up analyses needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6103f74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
